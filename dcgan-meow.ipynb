{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages\n",
    "- numpy, tensorflow, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Meow Dataset\n",
    "- 64x64 meow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainimg', 'trainlabel', 'testimg', 'testlabel', 'imgsize', 'use_gray', 'categories']\n",
      "Training images:  (3647, 12288)\n",
      "Test images:  (912, 12288)\n",
      "All images:  (4559, 12288)\n"
     ]
    }
   ],
   "source": [
    "meow_data_path = './data/meow_64.npz'\n",
    "meow_dataset = np.load(meow_data_path)\n",
    "\n",
    "print(meow_dataset.files)\n",
    "\n",
    "# parse dataset\n",
    "X_train = meow_dataset['trainimg']\n",
    "X_test = meow_dataset['testimg']\n",
    "X_ = np.append(X_train, X_test, axis=0)\n",
    "\n",
    "print(\"Training images: \", X_train.shape)\n",
    "print(\"Test images: \", X_test.shape)\n",
    "print(\"All images: \", X_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (4559, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "n_data = X_.shape[0]\n",
    "img_dim = meow_dataset['imgsize']\n",
    "\n",
    "X = np.reshape(X_, (n_data, img_dim[0], img_dim[1], 3))\n",
    "print(\"data shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN\n",
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = 3\n",
    "g_sizes = {\n",
    "    'z': 100,\n",
    "    'conv_layers': [\n",
    "        (512, 5, 2, True),\n",
    "        (256, 5, 2, True),\n",
    "        (128, 5, 2, True),\n",
    "        (64, 5, 2, True),\n",
    "        (colors, 5, 2, False)\n",
    "    ],\n",
    "    'dense_layers': [],\n",
    "    'output_activation': tf.tanh,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers = g_sizes['conv_layers']\n",
    "\n",
    "len(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generator(Z, img_length, g_sizes, is_training=True):\n",
    "    # dimensions\n",
    "    latent_dim = g_sizes['z']\n",
    "\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        # determine the size of the data at each step\n",
    "        dims = [img_length]\n",
    "        dim = img_length\n",
    "        n_conv_layers = len(g_sizes['conv_layers'])\n",
    "\n",
    "        for _, _, stride, _ in reversed(g_sizes['conv_layers'][1:]):\n",
    "            dim = int(np.ceil(float(dim) / stride))\n",
    "            dims.append(dim)\n",
    "\n",
    "        dims = list(reversed(dims))\n",
    "        print(\"dims: \", dims)\n",
    "        g_dims = dims\n",
    "\n",
    "        # output may use tanh or sigmoid\n",
    "        num_relues = n_conv_layers - 1\n",
    "        activation_functions = [tf.nn.relu]*num_relues + [g_sizes['output_activation']]\n",
    "\n",
    "        print('---- generator net ----')\n",
    "        for i in range(n_conv_layers):\n",
    "            # generator network setting \n",
    "            name = \"deconv_layer_%s\" % i\n",
    "            mo, filter_size, stride, apply_batch_norm = g_sizes['conv_layers'][i]\n",
    "            f = activation_functions[i]\n",
    "            output_shape = [None, dims[i], dims[i], mo]\n",
    "            print(\"output shape:\", output_shape)\n",
    "\n",
    "            # build generator network\n",
    "            if i == 0:\n",
    "                net = slim.fully_connected(Z, mo*dims[i]*dims[i])\n",
    "                net = tf.reshape(net, (-1, dims[i], dims[i], mo))\n",
    "            else:\n",
    "                net = slim.conv2d_transpose(inputs=net, num_outputs=mo,\n",
    "                                            kernel_size=filter_size, stride=stride, \n",
    "                                            activation_fn=f, scope=name)\n",
    "            if apply_batch_norm:\n",
    "                net = slim.batch_norm(net, is_training=is_training, scope=name+'_bn')\n",
    "            mi = mo\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims:  [4, 8, 16, 32, 64]\n",
      "---- generator net ----\n",
      "output shape: [None, 4, 4, 512]\n",
      "output shape: [None, 8, 8, 256]\n",
      "output shape: [None, 16, 16, 128]\n",
      "output shape: [None, 32, 32, 64]\n",
      "output shape: [None, 64, 64, 3]\n",
      "(10, 100)\n",
      "(10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "img_length = 64\n",
    "Z = tf.placeholder(tf.float32, shape=(None, 100), name='Z')\n",
    "\n",
    "sample_images = generator(Z, img_length, g_sizes)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sample_z = np.random.random((10,100))\n",
    "print(sample_z.shape)\n",
    "\n",
    "test_X_hat = sess.run(sample_images, feed_dict={Z: sample_z})\n",
    "print(test_X_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sizes = {\n",
    "    'conv_layers': [\n",
    "        (64, 5, 2, False),\n",
    "        (128, 5, 2, True),\n",
    "        (256, 5, 2, True),\n",
    "        (512, 5, 2, True)\n",
    "    ],\n",
    "    'dense_layers': [],\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 5 2 False\n",
      "conv_0 shape :  (?, 32, 32, 64)\n",
      "128 5 2 True\n",
      "conv_1 shape :  (?, 16, 16, 128)\n",
      "256 5 2 True\n",
      "conv_2 shape :  (?, 8, 8, 256)\n",
      "512 5 2 True\n",
      "conv_3 shape :  (?, 4, 4, 512)\n",
      "fc shape:  (?, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, (None, img_length, img_length, 3), name='x')\n",
    "is_training = True\n",
    "\n",
    "# def discriminator(x, img_length, d_sizes):\n",
    "'''build discriminator'''\n",
    "mi = 3\n",
    "dim = img_length\n",
    "\n",
    "for i, (mo, filter_size, stride, apply_batch_norm) in enumerate(d_sizes['conv_layers']):\n",
    "    name = 'conv_%s' % i\n",
    "#     print(mo, filter_size, stride, apply_batch_norm)\n",
    "    with slim.arg_scope([slim.conv2d], padding='SAME',\n",
    "                       weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                       weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "                       activation_fn=tf.nn.relu):\n",
    "        if i == 0:\n",
    "            net = slim.conv2d(x, mo, [filter_size, filter_size], stride=stride, scope=name)\n",
    "        else:\n",
    "            net = slim.conv2d(net, mo, [filter_size, filter_size], stride=stride, scope=name)\n",
    "        if apply_batch_norm:\n",
    "            net = slim.batch_norm(net, is_training=is_training, scope=name+'_bn')\n",
    "        print(name, \"shape : \", net.shape)\n",
    "        \n",
    "net = slim.flatten(net)\n",
    "logits = slim.fully_connected(net, 1, scope=\"fc\", activation_fn=None)\n",
    "print(\"fc shape: \", logits.shape)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Flatten/Reshape:0' shape=(?, 8192) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fc/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "test_input = np.random.random((10,64,64,3))\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_inputs = np.random.random((10,64,64,3))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "logits_ = sess.run(logits, feed_dict={x: test_inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01259434]\n",
      " [ 0.50866759]\n",
      " [ 0.03478894]\n",
      " [ 0.75325912]\n",
      " [-0.23173884]\n",
      " [ 1.11670589]\n",
      " [-0.86125094]\n",
      " [-0.16755843]\n",
      " [ 0.80265462]\n",
      " [ 2.14541936]]\n"
     ]
    }
   ],
   "source": [
    "print(logits_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
